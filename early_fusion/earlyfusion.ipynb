{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd563b7d-32c6-4899-bf36-ba2f564a541f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa24be2f-b46e-45af-9ab4-deb58c0842a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_embeddings = pd.read_csv('tweet_embeddings_fasttext (1).csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c879333-fb5d-4594-9b0c-b2b143a91d4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.131154</td>\n",
       "      <td>0.176437</td>\n",
       "      <td>-0.345513</td>\n",
       "      <td>-0.255645</td>\n",
       "      <td>-0.268259</td>\n",
       "      <td>-0.113330</td>\n",
       "      <td>0.346411</td>\n",
       "      <td>0.280881</td>\n",
       "      <td>0.091181</td>\n",
       "      <td>0.093783</td>\n",
       "      <td>...</td>\n",
       "      <td>0.277954</td>\n",
       "      <td>0.140248</td>\n",
       "      <td>0.344676</td>\n",
       "      <td>-0.445408</td>\n",
       "      <td>-0.352575</td>\n",
       "      <td>-0.182875</td>\n",
       "      <td>0.093665</td>\n",
       "      <td>-0.021464</td>\n",
       "      <td>0.253890</td>\n",
       "      <td>0.084544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.169417</td>\n",
       "      <td>0.307325</td>\n",
       "      <td>-0.231729</td>\n",
       "      <td>-0.155665</td>\n",
       "      <td>0.259054</td>\n",
       "      <td>0.003477</td>\n",
       "      <td>-0.043010</td>\n",
       "      <td>0.357226</td>\n",
       "      <td>0.152994</td>\n",
       "      <td>-0.008231</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.022121</td>\n",
       "      <td>-0.116841</td>\n",
       "      <td>0.069255</td>\n",
       "      <td>-0.445681</td>\n",
       "      <td>-0.187835</td>\n",
       "      <td>-0.149462</td>\n",
       "      <td>-0.124341</td>\n",
       "      <td>-0.118815</td>\n",
       "      <td>0.147849</td>\n",
       "      <td>-0.199896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.138547</td>\n",
       "      <td>0.341559</td>\n",
       "      <td>-0.084787</td>\n",
       "      <td>-0.167813</td>\n",
       "      <td>0.018742</td>\n",
       "      <td>0.048837</td>\n",
       "      <td>0.257246</td>\n",
       "      <td>0.373903</td>\n",
       "      <td>0.081103</td>\n",
       "      <td>0.166825</td>\n",
       "      <td>...</td>\n",
       "      <td>0.154594</td>\n",
       "      <td>-0.081027</td>\n",
       "      <td>0.102492</td>\n",
       "      <td>-0.189723</td>\n",
       "      <td>-0.259918</td>\n",
       "      <td>-0.078361</td>\n",
       "      <td>-0.055360</td>\n",
       "      <td>-0.008773</td>\n",
       "      <td>-0.043591</td>\n",
       "      <td>-0.041153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.127805</td>\n",
       "      <td>-0.033286</td>\n",
       "      <td>-0.437047</td>\n",
       "      <td>-0.214258</td>\n",
       "      <td>0.127682</td>\n",
       "      <td>0.120750</td>\n",
       "      <td>0.130697</td>\n",
       "      <td>0.667437</td>\n",
       "      <td>0.171993</td>\n",
       "      <td>0.086973</td>\n",
       "      <td>...</td>\n",
       "      <td>0.111984</td>\n",
       "      <td>-0.016443</td>\n",
       "      <td>0.002395</td>\n",
       "      <td>-0.040961</td>\n",
       "      <td>-0.259274</td>\n",
       "      <td>-0.101791</td>\n",
       "      <td>0.047825</td>\n",
       "      <td>-0.219438</td>\n",
       "      <td>-0.001052</td>\n",
       "      <td>-0.059632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.127158</td>\n",
       "      <td>-0.130968</td>\n",
       "      <td>-0.359310</td>\n",
       "      <td>0.160072</td>\n",
       "      <td>0.130705</td>\n",
       "      <td>0.106213</td>\n",
       "      <td>0.176697</td>\n",
       "      <td>0.663304</td>\n",
       "      <td>-0.140670</td>\n",
       "      <td>0.157855</td>\n",
       "      <td>...</td>\n",
       "      <td>0.156714</td>\n",
       "      <td>0.093034</td>\n",
       "      <td>0.238774</td>\n",
       "      <td>-0.217899</td>\n",
       "      <td>-0.372566</td>\n",
       "      <td>0.098520</td>\n",
       "      <td>-0.182570</td>\n",
       "      <td>-0.015313</td>\n",
       "      <td>0.076258</td>\n",
       "      <td>-0.195156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149818</th>\n",
       "      <td>0.016122</td>\n",
       "      <td>-0.064021</td>\n",
       "      <td>-0.274872</td>\n",
       "      <td>-0.266635</td>\n",
       "      <td>0.082966</td>\n",
       "      <td>-0.151720</td>\n",
       "      <td>0.022459</td>\n",
       "      <td>0.528668</td>\n",
       "      <td>-0.151650</td>\n",
       "      <td>0.259676</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.133512</td>\n",
       "      <td>0.076022</td>\n",
       "      <td>0.261689</td>\n",
       "      <td>-0.122246</td>\n",
       "      <td>-0.205489</td>\n",
       "      <td>-0.202032</td>\n",
       "      <td>0.078283</td>\n",
       "      <td>-0.229029</td>\n",
       "      <td>0.102484</td>\n",
       "      <td>-0.075418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149819</th>\n",
       "      <td>-0.209446</td>\n",
       "      <td>0.314888</td>\n",
       "      <td>-0.118129</td>\n",
       "      <td>-0.019049</td>\n",
       "      <td>0.047566</td>\n",
       "      <td>0.048467</td>\n",
       "      <td>0.134524</td>\n",
       "      <td>0.406433</td>\n",
       "      <td>0.125752</td>\n",
       "      <td>0.226369</td>\n",
       "      <td>...</td>\n",
       "      <td>0.112518</td>\n",
       "      <td>-0.059568</td>\n",
       "      <td>0.262636</td>\n",
       "      <td>-0.278639</td>\n",
       "      <td>-0.157052</td>\n",
       "      <td>-0.063921</td>\n",
       "      <td>-0.138517</td>\n",
       "      <td>-0.015711</td>\n",
       "      <td>-0.019647</td>\n",
       "      <td>0.036563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149820</th>\n",
       "      <td>0.085293</td>\n",
       "      <td>0.206933</td>\n",
       "      <td>-0.199941</td>\n",
       "      <td>0.028921</td>\n",
       "      <td>0.068424</td>\n",
       "      <td>-0.124647</td>\n",
       "      <td>0.216909</td>\n",
       "      <td>0.479162</td>\n",
       "      <td>0.005471</td>\n",
       "      <td>0.109133</td>\n",
       "      <td>...</td>\n",
       "      <td>0.121173</td>\n",
       "      <td>-0.190553</td>\n",
       "      <td>0.180402</td>\n",
       "      <td>-0.084746</td>\n",
       "      <td>-0.192854</td>\n",
       "      <td>-0.135292</td>\n",
       "      <td>0.030228</td>\n",
       "      <td>-0.198240</td>\n",
       "      <td>0.041141</td>\n",
       "      <td>-0.140962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149821</th>\n",
       "      <td>-0.057220</td>\n",
       "      <td>0.052274</td>\n",
       "      <td>-0.224430</td>\n",
       "      <td>-0.155152</td>\n",
       "      <td>0.057795</td>\n",
       "      <td>-0.035073</td>\n",
       "      <td>0.220327</td>\n",
       "      <td>0.539429</td>\n",
       "      <td>0.057153</td>\n",
       "      <td>0.153490</td>\n",
       "      <td>...</td>\n",
       "      <td>0.168030</td>\n",
       "      <td>-0.120164</td>\n",
       "      <td>0.065945</td>\n",
       "      <td>-0.172835</td>\n",
       "      <td>-0.217492</td>\n",
       "      <td>-0.115228</td>\n",
       "      <td>0.086340</td>\n",
       "      <td>-0.105147</td>\n",
       "      <td>-0.127252</td>\n",
       "      <td>-0.064776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149822</th>\n",
       "      <td>-0.202955</td>\n",
       "      <td>-0.068002</td>\n",
       "      <td>-0.314515</td>\n",
       "      <td>-0.091731</td>\n",
       "      <td>0.089442</td>\n",
       "      <td>-0.001611</td>\n",
       "      <td>0.211516</td>\n",
       "      <td>0.670103</td>\n",
       "      <td>0.033994</td>\n",
       "      <td>0.073545</td>\n",
       "      <td>...</td>\n",
       "      <td>0.138255</td>\n",
       "      <td>-0.028827</td>\n",
       "      <td>0.023780</td>\n",
       "      <td>-0.214466</td>\n",
       "      <td>-0.276430</td>\n",
       "      <td>0.086018</td>\n",
       "      <td>0.150688</td>\n",
       "      <td>-0.153413</td>\n",
       "      <td>-0.014019</td>\n",
       "      <td>-0.075570</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>149823 rows Ã— 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0         1         2         3         4         5         6  \\\n",
       "0      -0.131154  0.176437 -0.345513 -0.255645 -0.268259 -0.113330  0.346411   \n",
       "1      -0.169417  0.307325 -0.231729 -0.155665  0.259054  0.003477 -0.043010   \n",
       "2      -0.138547  0.341559 -0.084787 -0.167813  0.018742  0.048837  0.257246   \n",
       "3      -0.127805 -0.033286 -0.437047 -0.214258  0.127682  0.120750  0.130697   \n",
       "4      -0.127158 -0.130968 -0.359310  0.160072  0.130705  0.106213  0.176697   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "149818  0.016122 -0.064021 -0.274872 -0.266635  0.082966 -0.151720  0.022459   \n",
       "149819 -0.209446  0.314888 -0.118129 -0.019049  0.047566  0.048467  0.134524   \n",
       "149820  0.085293  0.206933 -0.199941  0.028921  0.068424 -0.124647  0.216909   \n",
       "149821 -0.057220  0.052274 -0.224430 -0.155152  0.057795 -0.035073  0.220327   \n",
       "149822 -0.202955 -0.068002 -0.314515 -0.091731  0.089442 -0.001611  0.211516   \n",
       "\n",
       "               7         8         9  ...        90        91        92  \\\n",
       "0       0.280881  0.091181  0.093783  ...  0.277954  0.140248  0.344676   \n",
       "1       0.357226  0.152994 -0.008231  ... -0.022121 -0.116841  0.069255   \n",
       "2       0.373903  0.081103  0.166825  ...  0.154594 -0.081027  0.102492   \n",
       "3       0.667437  0.171993  0.086973  ...  0.111984 -0.016443  0.002395   \n",
       "4       0.663304 -0.140670  0.157855  ...  0.156714  0.093034  0.238774   \n",
       "...          ...       ...       ...  ...       ...       ...       ...   \n",
       "149818  0.528668 -0.151650  0.259676  ... -0.133512  0.076022  0.261689   \n",
       "149819  0.406433  0.125752  0.226369  ...  0.112518 -0.059568  0.262636   \n",
       "149820  0.479162  0.005471  0.109133  ...  0.121173 -0.190553  0.180402   \n",
       "149821  0.539429  0.057153  0.153490  ...  0.168030 -0.120164  0.065945   \n",
       "149822  0.670103  0.033994  0.073545  ...  0.138255 -0.028827  0.023780   \n",
       "\n",
       "              93        94        95        96        97        98        99  \n",
       "0      -0.445408 -0.352575 -0.182875  0.093665 -0.021464  0.253890  0.084544  \n",
       "1      -0.445681 -0.187835 -0.149462 -0.124341 -0.118815  0.147849 -0.199896  \n",
       "2      -0.189723 -0.259918 -0.078361 -0.055360 -0.008773 -0.043591 -0.041153  \n",
       "3      -0.040961 -0.259274 -0.101791  0.047825 -0.219438 -0.001052 -0.059632  \n",
       "4      -0.217899 -0.372566  0.098520 -0.182570 -0.015313  0.076258 -0.195156  \n",
       "...          ...       ...       ...       ...       ...       ...       ...  \n",
       "149818 -0.122246 -0.205489 -0.202032  0.078283 -0.229029  0.102484 -0.075418  \n",
       "149819 -0.278639 -0.157052 -0.063921 -0.138517 -0.015711 -0.019647  0.036563  \n",
       "149820 -0.084746 -0.192854 -0.135292  0.030228 -0.198240  0.041141 -0.140962  \n",
       "149821 -0.172835 -0.217492 -0.115228  0.086340 -0.105147 -0.127252 -0.064776  \n",
       "149822 -0.214466 -0.276430  0.086018  0.150688 -0.153413 -0.014019 -0.075570  \n",
       "\n",
       "[149823 rows x 100 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "46ca552e-5896-4847-a479-e8ccb122857f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a92de34e-a77b-410f-8652-9296db9dea57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e68d7389-9953-4f2e-911e-04ca31a03d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_ids = np.load('sample_img_ids.npy', allow_pickle=True)\n",
    "images = np.load('sample_labels.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "06b4785b-8409-44db-9d3e-ce9bfb892fa1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(image_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2a414d18-0d3f-47d8-8863-5916353897c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "555502cc-4f7e-4922-84ae-03f310b1db23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "149823"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "32b531f6-bc3d-4945-8398-77564f377aaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "149823"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(image_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ff1d9afb-5d8a-479d-b4e2-cdcd178094bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "149823"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ac62bd4f-dcad-4f8f-a63f-171d3a29311b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6350949d-7dad-4202-82de-cf9de292ede2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['1107737959011368960', '1105399620065263616',\n",
       "       '1108294579995009024', ..., '1109615951765475328',\n",
       "       '1107402117889908737', '1108536126967558144'], dtype='<U19')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a7eb7066-e399-4848-9529-d6658a0fba67",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_features = np.load('sample_features.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ebb92024-e1e3-4411-9e26-f2b30678a1af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(149823, 1280)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "98d0f6c5-00ba-42c7-8360-2f06e41de27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b797d69b-9b50-45b9-b38f-02bd97c52b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "51556172-836c-479a-a663-b37472052153",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_embeddings_reduced = pca.fit_transform(sample_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7427f7c4-7793-4e45-a507-50c3ab28b304",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(149823, 100)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_embeddings_reduced.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2d1cb72b-a81f-4510-8d61-b35370b7b7b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(149823, 100)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "text_embeddings = df_embeddings.values\n",
    "text_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b7e8aa9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(149823, 200)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fused_embeddings = np.hstack((image_embeddings_reduced, text_embeddings))\n",
    "fused_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7959757e-8f5e-491d-b051-f17f0cd120aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0c214e61-7c65-4309-ba07-5d45c215bfe9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(149823,)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "15cb6236-e423-4910-bece-40674e597922",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "351a4f6b-f6dc-401b-a085-f6c19cd04c4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: (119858, 200), Test set: (29965, 200)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(fused_embeddings, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n",
    "\n",
    "print(f\"Train set: {X_train.shape}, Test set: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4d908310-b0db-42a4-a4ba-a976266bab7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e05e9863-d271-42fc-a6b9-d6f8ead57290",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9.4\n"
     ]
    }
   ],
   "source": [
    "import dhg\n",
    "print(dhg.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9e0f360e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"partial_hyperedges.pkl\", \"rb\") as f:\n",
    "    hyperedges = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ad1864f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dhg import Hypergraph\n",
    "import torch\n",
    "\n",
    "num_nodes = max(max(e) for e in hyperedges) + 1\n",
    "\n",
    "hg = Hypergraph(\n",
    "    num_v=num_nodes,\n",
    "    e_list=hyperedges,\n",
    "    device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "46dc4cf3-f0b9-47f8-9128-b0f9a4b5fabb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DeepHateSpeechHGNN(\n",
      "  (hgnn1): HGNN(\n",
      "    (layers): ModuleList(\n",
      "      (0): HGNNConv(\n",
      "        (act): ReLU(inplace=True)\n",
      "        (drop): Dropout(p=0.5, inplace=False)\n",
      "        (theta): Linear(in_features=200, out_features=256, bias=True)\n",
      "      )\n",
      "      (1): HGNNConv(\n",
      "        (act): ReLU(inplace=True)\n",
      "        (drop): Dropout(p=0.5, inplace=False)\n",
      "        (theta): Linear(in_features=256, out_features=256, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (hgnn2): HGNN(\n",
      "    (layers): ModuleList(\n",
      "      (0-1): 2 x HGNNConv(\n",
      "        (act): ReLU(inplace=True)\n",
      "        (drop): Dropout(p=0.5, inplace=False)\n",
      "        (theta): Linear(in_features=256, out_features=256, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (batch_norm1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (batch_norm2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fc1): Linear(in_features=256, out_features=128, bias=True)\n",
      "  (fc2): Linear(in_features=128, out_features=2, bias=True)\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      "  (relu): ReLU()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from dhg.models import HGNN\n",
    "from torch.optim import Adam\n",
    "\n",
    "class DeepHateSpeechHGNN(nn.Module):\n",
    "    def __init__(self, in_dim, hidden_dim, num_classes, dropout=0.5):\n",
    "        super().__init__()\n",
    "        self.hgnn1 = HGNN(in_dim, hidden_dim, hidden_dim)\n",
    "        self.hgnn2 = HGNN(hidden_dim, hidden_dim, hidden_dim)\n",
    "\n",
    "        self.batch_norm1 = nn.BatchNorm1d(hidden_dim)\n",
    "        self.batch_norm2 = nn.BatchNorm1d(hidden_dim)\n",
    "\n",
    "        self.fc1 = nn.Linear(hidden_dim, hidden_dim // 2)\n",
    "        self.fc2 = nn.Linear(hidden_dim // 2, num_classes)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x, hg):\n",
    "        x = self.hgnn1(x, hg)\n",
    "        x = self.batch_norm1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x = self.hgnn2(x, hg)\n",
    "        x = self.batch_norm2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "in_dim = X_train.shape[1]  \n",
    "hidden_dim = 256  \n",
    "num_classes = 2  \n",
    "\n",
    "model = DeepHateSpeechHGNN(in_dim, hidden_dim, num_classes)\n",
    "optimizer = Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3f38885d-eaac-4363-9597-de945e7d8603",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Loss: 0.8123\n",
      "Epoch [2/20], Loss: 0.6729\n",
      "Epoch [3/20], Loss: 0.6091\n",
      "Epoch [4/20], Loss: 0.5842\n",
      "Epoch [5/20], Loss: 0.5802\n",
      "Epoch [6/20], Loss: 0.5863\n",
      "Epoch [7/20], Loss: 0.5891\n",
      "Epoch [8/20], Loss: 0.5876\n",
      "Epoch [9/20], Loss: 0.5819\n",
      "Epoch [10/20], Loss: 0.5745\n",
      "Epoch [11/20], Loss: 0.5677\n",
      "Epoch [12/20], Loss: 0.5648\n",
      "Epoch [13/20], Loss: 0.5632\n",
      "Epoch [14/20], Loss: 0.5638\n",
      "Epoch [15/20], Loss: 0.5642\n",
      "Epoch [16/20], Loss: 0.5646\n",
      "Epoch [17/20], Loss: 0.5635\n",
      "Epoch [18/20], Loss: 0.5627\n",
      "Epoch [19/20], Loss: 0.5619\n",
      "Epoch [20/20], Loss: 0.5599\n"
     ]
    }
   ],
   "source": [
    "def train_model(model, X_train_tensor, y_train_tensor, hg, epochs=200):\n",
    "    model.train()\n",
    "    optimizer = Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        optimizer.zero_grad()\n",
    "        output = model(X_train_tensor, hg)\n",
    "\n",
    "        loss = F.cross_entropy(output, y_train_tensor)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}\")\n",
    "\n",
    "train_model(model, X_train_tensor, y_train_tensor, hg, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "53344bc5-c5ba-4247-b529-d1ed7f8d4c9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([29965, 200])\n",
      "torch.Size([29965])\n"
     ]
    }
   ],
   "source": [
    "print(X_test_tensor.shape)\n",
    "print(y_test_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0c808856-79df-43b8-ac98-29c6c7933a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"partial_test_hyperedges.pkl\", \"rb\") as f:\n",
    "    test_hyperedges = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f7d305d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "num_nodes = max(max(e) for e in test_hyperedges) + 1\n",
    "\n",
    "test_hg = Hypergraph(\n",
    "    num_v=num_nodes,\n",
    "    e_list=test_hyperedges,\n",
    "    device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "af6e34f9-65fc-4931-aba5-3638eafdf4c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.5920, Test Accuracy: 75.22%\n"
     ]
    }
   ],
   "source": [
    "def test_model(model, X_test_tensor, y_test_tensor, test_hg):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        output = model(X_test_tensor, test_hg)\n",
    "\n",
    "        loss = F.cross_entropy(output, y_test_tensor)\n",
    "\n",
    "        _, predicted = torch.max(output, 1)\n",
    "        total += y_test_tensor.size(0)\n",
    "        correct += (predicted == y_test_tensor).sum().item()\n",
    "\n",
    "    acc = correct / total\n",
    "    print(f\"Test Loss: {loss.item():.4f}, Test Accuracy: {acc * 100:.2f}%\")\n",
    "\n",
    "test_model(model, X_test_tensor, y_test_tensor, test_hg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
