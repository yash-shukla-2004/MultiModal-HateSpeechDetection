{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a6c7dd5hpdcy",
        "outputId": "0e00304a-5e87-4a3d-806d-baf29a549e1d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                   clean_tweet_2  label\n",
            "0                                          nigga      4\n",
            "1                                horses retarded      5\n",
            "2  nigga momma youngboy spitting real shit nigga      0\n",
            "3            rt xxsugvngxx ran holy nigga today       1\n",
            "4                       everybody calling nigger      1\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "data = pd.read_csv(\"textual_data_an1_cleaned_final.csv\")\n",
        "\n",
        "print(data.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "073iG6ZgsJM3",
        "outputId": "00f53e70-cb26-4b74-c745-ba855e799409"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: gensim in /Users/admin/Library/Python/3.9/lib/python/site-packages (4.3.3)\n",
            "Requirement already satisfied: numpy<2.0,>=1.18.5 in /Users/admin/Library/Python/3.9/lib/python/site-packages (from gensim) (1.24.4)\n",
            "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /Users/admin/Library/Python/3.9/lib/python/site-packages (from gensim) (1.13.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /Users/admin/Library/Python/3.9/lib/python/site-packages (from gensim) (7.1.0)\n",
            "Requirement already satisfied: wrapt in /Users/admin/Library/Python/3.9/lib/python/site-packages (from smart-open>=1.8.1->gensim) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install gensim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "id": "CKRXLYgVsOUe",
        "outputId": "44f43c8a-a6ad-47e1-91cc-63f739bb8d37"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: numpy==1.24.4 in /Users/admin/Library/Python/3.9/lib/python/site-packages (1.24.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install numpy==1.24.4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wBneVZyY2qXa",
        "outputId": "2aacc62d-1c0b-4fb6-a1cd-72d45bd3899c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of sentences: 149822\n",
            "Number of labels: 149822\n"
          ]
        }
      ],
      "source": [
        "filtered_data = data.dropna(subset=['clean_tweet_2']).copy()\n",
        "\n",
        "# Now extract both in sync\n",
        "sentences = filtered_data['clean_tweet_2'].astype(str).tolist()\n",
        "y = filtered_data['label'].astype(int).tolist()\n",
        "\n",
        "# Optional: binarize the labels\n",
        "y = [1 if label != 0 else 0 for label in y]\n",
        "\n",
        "# Confirm\n",
        "print(\"Number of sentences:\", len(sentences))\n",
        "print(\"Number of labels:\", len(y))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZKoB7RRJpqkG",
        "outputId": "21e4b450-3bb7-4c44-af86-1cd199d65ede"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /Users/admin/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "from gensim.models import Word2Vec\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "import nltk\n",
        "\n",
        "# Verify if 'punkt' is available\n",
        "nltk.download('punkt')\n",
        "\n",
        "tokenized_sentences = [sentence.split() for sentence in sentences]\n",
        "tokenizer = RegexpTokenizer(r'\\w+')\n",
        "tokenized_sentences = [tokenizer.tokenize(str(sentence).lower()) for sentence in sentences]\n",
        "\n",
        "model = Word2Vec(sentences=tokenized_sentences, vector_size=100, window=5, min_count=1, sg=1, epochs=10)\n",
        "\n",
        "model.save(\"word2vec_model.model\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xNPKv6Eh2Gg5",
        "outputId": "a7bdd1e4-843e-42c8-e7d6-5fba9f009a11"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of sentences: 149822\n",
            "Number of labels: 149822\n"
          ]
        }
      ],
      "source": [
        "print(\"Number of sentences:\", len(sentences))\n",
        "print(\"Number of labels:\", len(y))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ctGotkBNp8Kt",
        "outputId": "3b33253c-e2ee-4e39-cfc2-814eb1410a8d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Vector for 'shit': [ 0.59024054  0.44312063  0.26723507 -0.03198092  0.44472104 -0.10116369\n",
            "  0.89917904  1.0842729  -0.5306927  -0.4790301   0.3180201  -0.792939\n",
            "  0.06238808 -0.01981799 -0.24417745 -0.20351759  0.60264194 -0.24241944\n",
            " -0.01383593 -0.6195277   0.281818    0.51503664  0.06008047 -0.5408794\n",
            "  0.00248451  0.6456495  -0.2748829  -0.203345    0.02977721 -0.16061579\n",
            " -0.20355712 -0.39545465  0.1350985   0.1073214  -0.06123455  0.13844776\n",
            "  0.31111005  0.10492787 -0.33643192 -0.3703423  -0.04687409 -0.17029992\n",
            "  0.02429629  0.00369885  0.5865334  -0.16098954 -0.45374376  0.21585917\n",
            "  0.24858278  0.6835139   0.05257368 -0.09547304 -0.27879342  0.2589546\n",
            " -0.17011829  0.4053065  -0.37350973  0.35203427 -0.17029418  0.22404604\n",
            " -0.36951676 -0.4289252   0.08512682 -0.29306898 -0.5937988   0.2071809\n",
            "  0.69880307  0.3374603  -0.27806512  0.4828797  -0.09829509  0.12977555\n",
            "  0.27532887 -0.23000939  0.1043769  -0.23460226  0.51300955  0.20568602\n",
            " -0.5910166  -0.41770282 -0.6940532   0.00985072 -0.0565483   0.04750269\n",
            " -0.21161148  0.18331917  0.53022844  0.7569271  -0.25701764  0.27337936\n",
            "  0.5991132  -0.16846392  0.5788385   0.45702118 -0.12184312  0.8781578\n",
            "  0.20416443 -0.6224114   0.13545577 -0.09656109]\n",
            "Words similar to 'shit': [('jp', 0.7119529247283936), ('fightin', 0.699695885181427), ('niggaz', 0.699230432510376), ('conversations', 0.6978231072425842), ('ahahaha', 0.6974876523017883), ('df', 0.6943559646606445), ('lmfaoo', 0.6943164467811584), ('shi', 0.6932376623153687), ('idgaf', 0.6912720799446106), ('ik', 0.6864832639694214)]\n"
          ]
        }
      ],
      "source": [
        "model = Word2Vec.load('word2vec_model.model')\n",
        "\n",
        "word_vector = model.wv['shit']\n",
        "print(\"Vector for 'shit':\", word_vector)\n",
        "\n",
        "similar_words = model.wv.most_similar('shit')\n",
        "print(\"Words similar to 'shit':\", similar_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6GBoSsARrD7C",
        "outputId": "4ec5fe0b-4d64-48b9-f249-5dd5c9c221d1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Words similar to 'hate': [('hates', 0.6982182860374451), ('fault', 0.6954658627510071), ('tew', 0.6827342510223389), ('pfp', 0.6811203360557556), ('istg', 0.6807213425636292)]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Check most similar words\n",
        "word = \"hate\"\n",
        "similar_words = model.wv.most_similar(word, topn=5)\n",
        "print(f\"Words similar to '{word}': {similar_words}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "oE18nLj2rXcp"
      },
      "outputs": [],
      "source": [
        "from gensim.models import FastText\n",
        "\n",
        "model = FastText(vector_size=100, window=5, min_count=1, sg=1, epochs=10)\n",
        "model.build_vocab(tokenized_sentences)\n",
        "model.train(tokenized_sentences, total_examples=len(tokenized_sentences), epochs=10)\n",
        "\n",
        "model.save(\"fasttext_model.model\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZdPUYctdsmwQ",
        "outputId": "6bc3a9e4-0277-4b44-f3e9-c301ebd2bb6b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Vector for 'hate': [-2.48300359e-01  1.09273024e-01 -6.71660364e-01  2.27219760e-01\n",
            "  5.62640250e-01  4.35334861e-01 -3.13606173e-01  1.45046905e-01\n",
            "  8.83883834e-01 -9.38965857e-01 -5.20260274e-01 -6.16742909e-01\n",
            "  1.44336507e-01  9.28647995e-01  2.25819033e-02 -2.20994428e-01\n",
            "  5.68438768e-01  5.45261726e-02 -1.63975745e-01 -1.06441414e+00\n",
            "  5.85953966e-02  8.31971586e-01  5.65044768e-02 -2.93443680e-01\n",
            " -6.65605485e-01 -5.01947463e-01  5.17006874e-01 -1.88412443e-02\n",
            "  1.31390961e-02  5.62422037e-01  8.77174914e-01  3.13685179e-01\n",
            "  2.81409472e-01 -2.45108113e-01  8.27184618e-02  1.84413284e-01\n",
            " -2.70475745e-01  7.68536210e-01 -3.24853063e-01 -6.84299786e-03\n",
            " -7.70946443e-01  4.64807063e-01  9.36575606e-02 -5.06642580e-01\n",
            " -5.20099342e-01 -3.12623739e-01 -5.40407717e-01  5.22264242e-01\n",
            "  2.42474422e-01 -1.88420102e-01  2.39965487e-02 -2.40830854e-01\n",
            " -3.88183519e-02  1.61293417e-03  5.61385788e-02 -2.33369589e-01\n",
            " -1.17531925e-01 -3.83623280e-02  3.10898662e-01  1.84851035e-01\n",
            "  3.99298370e-01 -8.20589066e-03  1.98454604e-01  3.75899613e-01\n",
            "  5.45479991e-02  7.06236660e-01 -2.11034585e-02  3.96103948e-01\n",
            " -4.57616597e-02  1.15646183e+00  6.25710934e-02  2.63853192e-01\n",
            "  4.19382453e-01 -4.35088158e-01  5.87080829e-02 -1.17196470e-01\n",
            "  6.55771673e-01 -3.21597844e-01  1.08841874e-01  3.33850570e-02\n",
            " -6.80096030e-01 -7.54253864e-02 -5.26484191e-01  4.48120892e-01\n",
            "  1.56172574e-01 -5.71991384e-01 -1.10734046e+00 -6.18310121e-04\n",
            "  3.83658893e-02  1.39674485e-01 -8.90088618e-01  2.28860155e-01\n",
            " -7.15296715e-02  2.01859847e-01  1.10852532e-01  4.32395667e-01\n",
            "  4.80758458e-01 -7.98500851e-02  1.84663281e-01 -8.59404281e-02]\n",
            "Similar words: [('haterz', 0.8705105781555176), ('yhate', 0.8700005412101746), ('hatee', 0.8631404042243958), ('ihate', 0.8565041422843933), ('haten', 0.8548374176025391), ('hateonme', 0.8413458466529846), ('luv2hate', 0.8390507698059082), ('hatejust', 0.8156735301017761), ('hatersgonnahate', 0.8136341571807861), ('haterswillhate', 0.8092218041419983)]\n"
          ]
        }
      ],
      "source": [
        "model = FastText.load(\"fasttext_model.model\")\n",
        "\n",
        "word_vector = model.wv['hate']\n",
        "print(\"Vector for 'hate':\", word_vector)\n",
        "\n",
        "similar_words = model.wv.most_similar('hate')\n",
        "print(\"Similar words:\", similar_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U_sDybV7skEo",
        "outputId": "2b2ce69a-9aee-48a1-8ce6-6c60b5de8662"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of X: (60373, 100)\n",
            "Shape of H: (60373, 149822)\n",
            "Feature Matrix Shape (X): (60373, 100)\n",
            "Incidence Matrix Shape (H): (60373, 149822)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from gensim.models import FastText\n",
        "from scipy.sparse import csr_matrix\n",
        "from collections import defaultdict\n",
        "\n",
        "# Load FastText model\n",
        "model = FastText.load(\"fasttext_model.model\")\n",
        "\n",
        "# Sample sentences\n",
        "sentences = data['clean_tweet_2']\n",
        "# Ensure all sentences are strings and handle NaN values\n",
        "sentences = [str(sentence) for sentence in sentences if pd.notnull(sentence)]\n",
        "\n",
        "# Create vocabulary\n",
        "vocab = list(model.wv.index_to_key)\n",
        "# Create a word-to-index dictionary for faster lookups\n",
        "word_to_index = defaultdict(lambda: -1, {word: i for i, word in enumerate(vocab)})\n",
        "\n",
        "# Create embedding matrix (X) - word embeddings\n",
        "embedding_dim = model.vector_size\n",
        "X = np.zeros((len(vocab), embedding_dim), dtype=np.float32)\n",
        "print(\"Shape of X:\", X.shape)\n",
        "for i, word in enumerate(vocab):\n",
        "    X[i] = model.wv[word]\n",
        "\n",
        "# Create hypergraph incidence matrix (H)\n",
        "num_sentences = len(sentences)\n",
        "H = np.zeros((len(vocab), num_sentences), dtype=np.float32)\n",
        "\n",
        "print(\"Shape of H:\", H.shape)\n",
        "\n",
        "for j, sentence in enumerate(sentences):\n",
        "    for word in sentence.split():\n",
        "        i = word_to_index[word]\n",
        "        if i != -1:\n",
        "            H[i, j] = 1\n",
        "\n",
        "# Convert to sparse matrices\n",
        "X_sparse = csr_matrix(X)  # Feature matrix\n",
        "H_sparse = csr_matrix(H)  # Hypergraph incidence matrix\n",
        "\n",
        "print(\"Feature Matrix Shape (X):\", X_sparse.shape)\n",
        "print(\"Incidence Matrix Shape (H):\", H_sparse.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ok98J9fpvcg3",
        "outputId": "1e4643ce-329f-4796-964b-812c35bf318b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: dhg in /Users/admin/Library/Python/3.9/lib/python/site-packages (0.9.4)\n",
            "Requirement already satisfied: matplotlib in /Users/admin/Library/Python/3.9/lib/python/site-packages (from dhg) (3.9.2)\n",
            "Requirement already satisfied: numpy in /Users/admin/Library/Python/3.9/lib/python/site-packages (from dhg) (1.24.4)\n",
            "Requirement already satisfied: optuna in /Users/admin/Library/Python/3.9/lib/python/site-packages (from dhg) (4.2.1)\n",
            "Requirement already satisfied: requests in /Users/admin/Library/Python/3.9/lib/python/site-packages (from dhg) (2.32.3)\n",
            "Requirement already satisfied: scikit-learn in /Users/admin/Library/Python/3.9/lib/python/site-packages (from dhg) (1.5.2)\n",
            "Requirement already satisfied: scipy<2.0,>=1.8 in /Users/admin/Library/Python/3.9/lib/python/site-packages (from dhg) (1.13.1)\n",
            "Collecting torch<2.0,>=1.12.1 (from dhg)\n",
            "  Using cached torch-1.13.1-cp39-none-macosx_11_0_arm64.whl.metadata (23 kB)\n",
            "Requirement already satisfied: typing-extensions in /Users/admin/Library/Python/3.9/lib/python/site-packages (from torch<2.0,>=1.12.1->dhg) (4.12.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /Users/admin/Library/Python/3.9/lib/python/site-packages (from matplotlib->dhg) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /Users/admin/Library/Python/3.9/lib/python/site-packages (from matplotlib->dhg) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /Users/admin/Library/Python/3.9/lib/python/site-packages (from matplotlib->dhg) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/admin/Library/Python/3.9/lib/python/site-packages (from matplotlib->dhg) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /Users/admin/Library/Python/3.9/lib/python/site-packages (from matplotlib->dhg) (24.1)\n",
            "Requirement already satisfied: pillow>=8 in /Users/admin/Library/Python/3.9/lib/python/site-packages (from matplotlib->dhg) (10.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /Users/admin/Library/Python/3.9/lib/python/site-packages (from matplotlib->dhg) (3.1.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /Users/admin/Library/Python/3.9/lib/python/site-packages (from matplotlib->dhg) (2.9.0.post0)\n",
            "Requirement already satisfied: importlib-resources>=3.2.0 in /Users/admin/Library/Python/3.9/lib/python/site-packages (from matplotlib->dhg) (6.4.5)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /Users/admin/Library/Python/3.9/lib/python/site-packages (from optuna->dhg) (1.15.2)\n",
            "Requirement already satisfied: colorlog in /Users/admin/Library/Python/3.9/lib/python/site-packages (from optuna->dhg) (6.9.0)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /Users/admin/Library/Python/3.9/lib/python/site-packages (from optuna->dhg) (2.0.40)\n",
            "Requirement already satisfied: tqdm in /Users/admin/Library/Python/3.9/lib/python/site-packages (from optuna->dhg) (4.67.1)\n",
            "Requirement already satisfied: PyYAML in /Users/admin/Library/Python/3.9/lib/python/site-packages (from optuna->dhg) (6.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/admin/Library/Python/3.9/lib/python/site-packages (from requests->dhg) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /Users/admin/Library/Python/3.9/lib/python/site-packages (from requests->dhg) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/admin/Library/Python/3.9/lib/python/site-packages (from requests->dhg) (1.26.19)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Users/admin/Library/Python/3.9/lib/python/site-packages (from requests->dhg) (2024.8.30)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /Users/admin/Library/Python/3.9/lib/python/site-packages (from scikit-learn->dhg) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /Users/admin/Library/Python/3.9/lib/python/site-packages (from scikit-learn->dhg) (3.5.0)\n",
            "Requirement already satisfied: Mako in /Users/admin/Library/Python/3.9/lib/python/site-packages (from alembic>=1.5.0->optuna->dhg) (1.3.9)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /Users/admin/Library/Python/3.9/lib/python/site-packages (from importlib-resources>=3.2.0->matplotlib->dhg) (3.20.1)\n",
            "Requirement already satisfied: six>=1.5 in /Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/site-packages (from python-dateutil>=2.7->matplotlib->dhg) (1.15.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /Users/admin/Library/Python/3.9/lib/python/site-packages (from Mako->alembic>=1.5.0->optuna->dhg) (2.1.5)\n",
            "Using cached torch-1.13.1-cp39-none-macosx_11_0_arm64.whl (53.2 MB)\n",
            "Installing collected packages: torch\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.5.1\n",
            "    Uninstalling torch-2.5.1:\n",
            "      Successfully uninstalled torch-2.5.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "lightning 2.5.0.post0 requires torch<4.0,>=2.1.0, but you have torch 1.13.1 which is incompatible.\n",
            "pytorch-lightning 2.5.0.post0 requires torch>=2.1.0, but you have torch 1.13.1 which is incompatible.\n",
            "torchaudio 2.5.1 requires torch==2.5.1, but you have torch 1.13.1 which is incompatible.\n",
            "torchmetrics 1.6.1 requires torch>=2.0.0, but you have torch 1.13.1 which is incompatible.\n",
            "torchvision 0.20.1 requires torch==2.5.1, but you have torch 1.13.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed torch-1.13.1\n"
          ]
        }
      ],
      "source": [
        "!pip install dhg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "214wRkk7vmy3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/admin/Library/Python/3.9/lib/python/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import dhg\n",
        "import torch\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from torch.nn.functional import one_hot\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader, TensorDataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "f2K_4xZN3W7x"
      },
      "outputs": [],
      "source": [
        "\n",
        "vocab = list(model.wv.index_to_key)\n",
        "\n",
        "from collections import defaultdict\n",
        "word_to_index = defaultdict(lambda: -1, {word: idx for idx, word in enumerate(vocab)})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LANjNXwM0K0M",
        "outputId": "acd25e11-d0a5-4a49-e7c6-0d439f19c349"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of hyperedges (tweets): 149822\n"
          ]
        }
      ],
      "source": [
        "hyperedges = []\n",
        "for sentence in sentences:\n",
        "    word_indices = list({word_to_index[word] for word in sentence.split() if word_to_index[word] != -1})\n",
        "    hyperedges.append(word_indices)\n",
        "\n",
        "print(f\"Number of hyperedges (tweets): {len(hyperedges)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "D2HFBLpX3P2O"
      },
      "outputs": [],
      "source": [
        "G = dhg.Hypergraph(num_v=len(vocab), e_list=hyperedges)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W3KnDuPw36KT",
        "outputId": "e324b1fd-b835-4732-c9d8-43ffe074ca8b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Feature matrix X shape: (60373, 100)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "embedding_dim = model.vector_size\n",
        "\n",
        "\n",
        "X = np.zeros((len(vocab), embedding_dim), dtype=np.float32)\n",
        "\n",
        "\n",
        "for i, word in enumerate(vocab):\n",
        "    X[i] = model.wv[word]\n",
        "\n",
        "print(\"Feature matrix X shape:\", X.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "R6O7T8RA3jNp"
      },
      "outputs": [],
      "source": [
        "num_edges = len(hyperedges)  # each tweet is a hyperedge\n",
        "\n",
        "train_idx, test_idx = train_test_split(\n",
        "    np.arange(num_edges),\n",
        "    test_size=0.2,\n",
        "    stratify=y,\n",
        "    random_state=42\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eMkNfRAg3nkI",
        "outputId": "6e372223-5035-4d9b-87b1-1e641407454f"
      },
      "outputs": [],
      "source": [
        "train_idx = torch.tensor(train_idx, dtype=torch.long)\n",
        "test_idx = torch.tensor(test_idx, dtype=torch.long)\n",
        "y = torch.tensor(y, dtype=torch.long)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "k4VTQi_Y6o9n"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "100\n"
          ]
        }
      ],
      "source": [
        "X_tensor = torch.tensor(X, dtype=torch.float)\n",
        "print(X_tensor.shape[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "2tZthliM64_h"
      },
      "outputs": [],
      "source": [
        "from dhg import Hypergraph\n",
        "hg = Hypergraph(len(vocab), hyperedges)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "v3vnYyyx8D3Q",
        "outputId": "bdc9370f-f9ba-45e1-bd80-3875f0af2168"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: dhg in /Users/admin/Library/Python/3.9/lib/python/site-packages (0.9.4)\n",
            "Requirement already satisfied: matplotlib in /Users/admin/Library/Python/3.9/lib/python/site-packages (from dhg) (3.9.2)\n",
            "Requirement already satisfied: numpy in /Users/admin/Library/Python/3.9/lib/python/site-packages (from dhg) (1.24.4)\n",
            "Requirement already satisfied: optuna in /Users/admin/Library/Python/3.9/lib/python/site-packages (from dhg) (4.2.1)\n",
            "Requirement already satisfied: requests in /Users/admin/Library/Python/3.9/lib/python/site-packages (from dhg) (2.32.3)\n",
            "Requirement already satisfied: scikit-learn in /Users/admin/Library/Python/3.9/lib/python/site-packages (from dhg) (1.5.2)\n",
            "Requirement already satisfied: scipy<2.0,>=1.8 in /Users/admin/Library/Python/3.9/lib/python/site-packages (from dhg) (1.13.1)\n",
            "Requirement already satisfied: torch<2.0,>=1.12.1 in /Users/admin/Library/Python/3.9/lib/python/site-packages (from dhg) (1.13.1)\n",
            "Requirement already satisfied: typing-extensions in /Users/admin/Library/Python/3.9/lib/python/site-packages (from torch<2.0,>=1.12.1->dhg) (4.12.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /Users/admin/Library/Python/3.9/lib/python/site-packages (from matplotlib->dhg) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /Users/admin/Library/Python/3.9/lib/python/site-packages (from matplotlib->dhg) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /Users/admin/Library/Python/3.9/lib/python/site-packages (from matplotlib->dhg) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/admin/Library/Python/3.9/lib/python/site-packages (from matplotlib->dhg) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /Users/admin/Library/Python/3.9/lib/python/site-packages (from matplotlib->dhg) (24.1)\n",
            "Requirement already satisfied: pillow>=8 in /Users/admin/Library/Python/3.9/lib/python/site-packages (from matplotlib->dhg) (10.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /Users/admin/Library/Python/3.9/lib/python/site-packages (from matplotlib->dhg) (3.1.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /Users/admin/Library/Python/3.9/lib/python/site-packages (from matplotlib->dhg) (2.9.0.post0)\n",
            "Requirement already satisfied: importlib-resources>=3.2.0 in /Users/admin/Library/Python/3.9/lib/python/site-packages (from matplotlib->dhg) (6.4.5)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /Users/admin/Library/Python/3.9/lib/python/site-packages (from optuna->dhg) (1.15.2)\n",
            "Requirement already satisfied: colorlog in /Users/admin/Library/Python/3.9/lib/python/site-packages (from optuna->dhg) (6.9.0)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /Users/admin/Library/Python/3.9/lib/python/site-packages (from optuna->dhg) (2.0.40)\n",
            "Requirement already satisfied: tqdm in /Users/admin/Library/Python/3.9/lib/python/site-packages (from optuna->dhg) (4.67.1)\n",
            "Requirement already satisfied: PyYAML in /Users/admin/Library/Python/3.9/lib/python/site-packages (from optuna->dhg) (6.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/admin/Library/Python/3.9/lib/python/site-packages (from requests->dhg) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /Users/admin/Library/Python/3.9/lib/python/site-packages (from requests->dhg) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/admin/Library/Python/3.9/lib/python/site-packages (from requests->dhg) (1.26.19)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Users/admin/Library/Python/3.9/lib/python/site-packages (from requests->dhg) (2024.8.30)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /Users/admin/Library/Python/3.9/lib/python/site-packages (from scikit-learn->dhg) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /Users/admin/Library/Python/3.9/lib/python/site-packages (from scikit-learn->dhg) (3.5.0)\n",
            "Requirement already satisfied: Mako in /Users/admin/Library/Python/3.9/lib/python/site-packages (from alembic>=1.5.0->optuna->dhg) (1.3.9)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /Users/admin/Library/Python/3.9/lib/python/site-packages (from importlib-resources>=3.2.0->matplotlib->dhg) (3.20.1)\n",
            "Requirement already satisfied: six>=1.5 in /Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/site-packages (from python-dateutil>=2.7->matplotlib->dhg) (1.15.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /Users/admin/Library/Python/3.9/lib/python/site-packages (from Mako->alembic>=1.5.0->optuna->dhg) (2.1.5)\n"
          ]
        }
      ],
      "source": [
        "!pip install -U dhg\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 322
        },
        "id": "FHsKZ0Bw71kc",
        "outputId": "5395fd1e-6730-462b-d700-fbdce8a88825"
      },
      "outputs": [],
      "source": [
        "from dhg.models import HGNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "3yVygULL7us5"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from dhg.models import HGNN\n",
        "\n",
        "class MyHGNN(nn.Module):\n",
        "    def __init__(self, in_dim, hidden_dim, out_dim):\n",
        "        super().__init__()\n",
        "        self.hgnn = HGNN(in_dim, hidden_dim, out_dim)\n",
        "\n",
        "    def forward(self, x, hg):\n",
        "        return self.hgnn(x, hg)\n",
        "\n",
        "in_dim = X_tensor.shape[1]     # embedding dimension (100 for FastText)\n",
        "hidden_dim = 64\n",
        "out_dim = 2                    # binary classification: hate or not\n",
        "\n",
        "model = MyHGNN(in_dim, hidden_dim, out_dim)\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "criterion = nn.CrossEntropyLoss()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "qq4ZP32L-P2W"
      },
      "outputs": [],
      "source": [
        "if isinstance(y, list):\n",
        "    y = torch.tensor(y, dtype=torch.long)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SXENqdRQ_B0R",
        "outputId": "a5dd0a90-ee4a-4965-d290-ec6083f01778"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Type of hyperedges: <class 'list'>\n",
            "Length of hyperedges: 149822\n"
          ]
        }
      ],
      "source": [
        "print(\"Type of hyperedges:\", type(hyperedges))\n",
        "print(\"Length of hyperedges:\", len(hyperedges))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4HhbJgq4_KLJ",
        "outputId": "386d330f-20f0-4268-e574-4c938b683be3"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'y' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43my\u001b[49m\u001b[38;5;241m.\u001b[39mshape\n",
            "\u001b[0;31mNameError\u001b[0m: name 'y' is not defined"
          ]
        }
      ],
      "source": [
        "y.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cBKYVB6b7C83",
        "outputId": "970d6ca0-3d89-40b6-ad9e-25ea8ebbdf00"
      },
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[30], line 18\u001b[0m\n\u001b[1;32m     14\u001b[0m         edge_out[e] \u001b[38;5;241m=\u001b[39m out[\u001b[38;5;28mlist\u001b[39m(nodes)]\u001b[38;5;241m.\u001b[39mmean(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     17\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(edge_out[train_idx], y[train_idx])\n\u001b[0;32m---> 18\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     22\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n",
            "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/_tensor.py:488\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    478\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    479\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    480\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    481\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    486\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    487\u001b[0m     )\n\u001b[0;32m--> 488\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    490\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/autograd/__init__.py:197\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    192\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    194\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    196\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 197\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "num_epochs = 20\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    out = model(X_tensor, hg)\n",
        "\n",
        "    # Aggregate node predictions to edge level (sentence-level)\n",
        "    edge_out = torch.zeros((len(hyperedges), out.shape[1]))\n",
        "\n",
        "    for e, nodes in enumerate(hyperedges):\n",
        "        if len(nodes) > 0:\n",
        "            edge_out[e] = out[list(nodes)].mean(dim=0)\n",
        "\n",
        "\n",
        "    loss = criterion(edge_out[train_idx], y[train_idx])\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        preds = edge_out[test_idx].argmax(dim=1)\n",
        "        acc = (preds == y[test_idx]).float().mean().item()\n",
        "    print(f\"Epoch {epoch+1}: Loss = {loss.item():.4f}, Test Accuracy = {acc:.4f}\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "irGGbDaLDpA9"
      },
      "outputs": [],
      "source": [
        "def predict_sentence(sentence, model, ft_model, vocab, X_tensor):\n",
        "    model.eval()\n",
        "    words = sentence.lower().split()\n",
        "\n",
        "    node_indices = [vocab[word] for word in words if word in vocab]\n",
        "\n",
        "    if not node_indices:\n",
        "        return \"No known words in sentence.\"\n",
        "\n",
        "\n",
        "    with torch.no_grad():\n",
        "        out = model(X_tensor, hg)  # shape: (num_nodes, out_dim)\n",
        "        sentence_embed = out[node_indices].mean(dim=0)  # average over node predictions\n",
        "        prediction = torch.argmax(sentence_embed).item()\n",
        "        probs = torch.softmax(sentence_embed, dim=0)\n",
        "\n",
        "    label = \"Hate Speech\" if prediction == 1 else \"Not Hate Speech\"\n",
        "    confidence = probs[prediction].item()\n",
        "\n",
        "    return f\"Prediction: {label} (confidence: {confidence:.4f})\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AXuDIg7eEFs3"
      },
      "outputs": [],
      "source": [
        "ft_model = FastText.load(\"fasttext_model.model\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pj3sspVvEUiH"
      },
      "outputs": [],
      "source": [
        "vocab_dict = {word: idx for idx, word in enumerate(vocab)}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lB_lqo-1DqRr",
        "outputId": "e30d497b-4e2e-4331-f2b4-b23154c04878"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Prediction: Not Hate Speech (confidence: 0.7355)\n"
          ]
        }
      ],
      "source": [
        "result = predict_sentence(\"nigga i hate tests\", model, ft_model, vocab_dict, X_tensor)\n",
        "print(result)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sRHgYvhv9W5l",
        "outputId": "0f754d55-a9e9-43d9-b321-0f1b49abdec5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "out shape: torch.Size([60373, 2])\n",
            "Number of hyperedges: 149822\n",
            "Sample hyperedge nodes: (0,)\n",
            "edge_out type: <class 'torch.Tensor'>\n",
            "edge_out shape: torch.Size([149822, 2])\n",
            "train_idx max: 149821 | len(train_idx): 119857\n",
            "y shape: torch.Size([149822]) | y dtype: torch.int64\n"
          ]
        }
      ],
      "source": [
        "print(\"out shape:\", out.shape)  # should be (num_nodes, out_dim)\n",
        "print(\"Number of hyperedges:\", len(hyperedges))\n",
        "print(\"Sample hyperedge nodes:\", hyperedges[0])\n",
        "\n",
        "print(\"edge_out type:\", type(edge_out))\n",
        "print(\"edge_out shape:\", edge_out.shape if isinstance(edge_out, torch.Tensor) else \"not tensor\")\n",
        "print(\"train_idx max:\", train_idx.max().item(), \"| len(train_idx):\", len(train_idx))\n",
        "print(\"y shape:\", y.shape, \"| y dtype:\", y.dtype)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yi2LSap_9Xbf",
        "outputId": "460767f1-7108-41f4-a53b-3f6b81b22e78"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Empty hyperedges: 14 / 149822\n"
          ]
        }
      ],
      "source": [
        "empty_count = sum([1 for e in hyperedges if len(e) == 0])\n",
        "print(f\"Empty hyperedges: {empty_count} / {len(hyperedges)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "torch.save(model.state_dict(), \"model_weights.pth\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
